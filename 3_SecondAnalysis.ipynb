{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas\n",
    "!pip install scikit-learn\n",
    "!pip install missingno\n",
    "!pip install Jinja2\n",
    "# !pip uninstall nbformat ipython plotly\n",
    "!pip install nbformat ipython plotly\n",
    "!pip install plotly\n",
    "# !pip install nbformat --upgrade\n",
    "!pip install geopandas\n",
    "!pip install shapely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### import libraries\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import missingno\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import datetime\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_LAT_LON_YEAR_WEEK</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>year</th>\n",
       "      <th>week_no</th>\n",
       "      <th>SulphurDioxide_SO2_column_number_density</th>\n",
       "      <th>SulphurDioxide_SO2_column_number_density_amf</th>\n",
       "      <th>SulphurDioxide_SO2_slant_column_number_density</th>\n",
       "      <th>SulphurDioxide_cloud_fraction</th>\n",
       "      <th>SulphurDioxide_sensor_azimuth_angle</th>\n",
       "      <th>...</th>\n",
       "      <th>Cloud_cloud_top_height</th>\n",
       "      <th>Cloud_cloud_base_pressure</th>\n",
       "      <th>Cloud_cloud_base_height</th>\n",
       "      <th>Cloud_cloud_optical_depth</th>\n",
       "      <th>Cloud_surface_albedo</th>\n",
       "      <th>Cloud_sensor_azimuth_angle</th>\n",
       "      <th>Cloud_sensor_zenith_angle</th>\n",
       "      <th>Cloud_solar_azimuth_angle</th>\n",
       "      <th>Cloud_solar_zenith_angle</th>\n",
       "      <th>emission</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_-0.510_29.290_2019_00</td>\n",
       "      <td>-0.51</td>\n",
       "      <td>29.29</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000108</td>\n",
       "      <td>0.603019</td>\n",
       "      <td>-0.000065</td>\n",
       "      <td>0.255668</td>\n",
       "      <td>-98.593887</td>\n",
       "      <td>...</td>\n",
       "      <td>3664.436218</td>\n",
       "      <td>61085.809570</td>\n",
       "      <td>2615.120483</td>\n",
       "      <td>15.568533</td>\n",
       "      <td>0.272292</td>\n",
       "      <td>-12.628986</td>\n",
       "      <td>35.632416</td>\n",
       "      <td>-138.786423</td>\n",
       "      <td>30.752140</td>\n",
       "      <td>3.750994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_-0.510_29.290_2019_01</td>\n",
       "      <td>-0.51</td>\n",
       "      <td>29.29</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.728214</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.130988</td>\n",
       "      <td>16.592861</td>\n",
       "      <td>...</td>\n",
       "      <td>3651.190311</td>\n",
       "      <td>66969.478735</td>\n",
       "      <td>3174.572424</td>\n",
       "      <td>8.690601</td>\n",
       "      <td>0.256830</td>\n",
       "      <td>30.359375</td>\n",
       "      <td>39.557633</td>\n",
       "      <td>-145.183930</td>\n",
       "      <td>27.251779</td>\n",
       "      <td>4.025176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_-0.510_29.290_2019_02</td>\n",
       "      <td>-0.51</td>\n",
       "      <td>29.29</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000514</td>\n",
       "      <td>0.748199</td>\n",
       "      <td>0.000385</td>\n",
       "      <td>0.110018</td>\n",
       "      <td>72.795837</td>\n",
       "      <td>...</td>\n",
       "      <td>4216.986492</td>\n",
       "      <td>60068.894448</td>\n",
       "      <td>3516.282669</td>\n",
       "      <td>21.103410</td>\n",
       "      <td>0.251101</td>\n",
       "      <td>15.377883</td>\n",
       "      <td>30.401823</td>\n",
       "      <td>-142.519545</td>\n",
       "      <td>26.193296</td>\n",
       "      <td>4.231381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_-0.510_29.290_2019_03</td>\n",
       "      <td>-0.51</td>\n",
       "      <td>29.29</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5228.507736</td>\n",
       "      <td>51064.547339</td>\n",
       "      <td>4180.973322</td>\n",
       "      <td>15.386899</td>\n",
       "      <td>0.262043</td>\n",
       "      <td>-11.293399</td>\n",
       "      <td>24.380357</td>\n",
       "      <td>-132.665828</td>\n",
       "      <td>28.829155</td>\n",
       "      <td>4.305286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_-0.510_29.290_2019_04</td>\n",
       "      <td>-0.51</td>\n",
       "      <td>29.29</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.000079</td>\n",
       "      <td>0.676296</td>\n",
       "      <td>-0.000048</td>\n",
       "      <td>0.121164</td>\n",
       "      <td>4.121269</td>\n",
       "      <td>...</td>\n",
       "      <td>3980.598120</td>\n",
       "      <td>63751.125781</td>\n",
       "      <td>3355.710107</td>\n",
       "      <td>8.114694</td>\n",
       "      <td>0.235847</td>\n",
       "      <td>38.532263</td>\n",
       "      <td>37.392979</td>\n",
       "      <td>-141.509805</td>\n",
       "      <td>22.204612</td>\n",
       "      <td>4.347317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID_LAT_LON_YEAR_WEEK  latitude  longitude  year  week_no  \\\n",
       "0  ID_-0.510_29.290_2019_00     -0.51      29.29  2019        0   \n",
       "1  ID_-0.510_29.290_2019_01     -0.51      29.29  2019        1   \n",
       "2  ID_-0.510_29.290_2019_02     -0.51      29.29  2019        2   \n",
       "3  ID_-0.510_29.290_2019_03     -0.51      29.29  2019        3   \n",
       "4  ID_-0.510_29.290_2019_04     -0.51      29.29  2019        4   \n",
       "\n",
       "   SulphurDioxide_SO2_column_number_density  \\\n",
       "0                                 -0.000108   \n",
       "1                                  0.000021   \n",
       "2                                  0.000514   \n",
       "3                                       NaN   \n",
       "4                                 -0.000079   \n",
       "\n",
       "   SulphurDioxide_SO2_column_number_density_amf  \\\n",
       "0                                      0.603019   \n",
       "1                                      0.728214   \n",
       "2                                      0.748199   \n",
       "3                                           NaN   \n",
       "4                                      0.676296   \n",
       "\n",
       "   SulphurDioxide_SO2_slant_column_number_density  \\\n",
       "0                                       -0.000065   \n",
       "1                                        0.000014   \n",
       "2                                        0.000385   \n",
       "3                                             NaN   \n",
       "4                                       -0.000048   \n",
       "\n",
       "   SulphurDioxide_cloud_fraction  SulphurDioxide_sensor_azimuth_angle  ...  \\\n",
       "0                       0.255668                           -98.593887  ...   \n",
       "1                       0.130988                            16.592861  ...   \n",
       "2                       0.110018                            72.795837  ...   \n",
       "3                            NaN                                  NaN  ...   \n",
       "4                       0.121164                             4.121269  ...   \n",
       "\n",
       "   Cloud_cloud_top_height  Cloud_cloud_base_pressure  Cloud_cloud_base_height  \\\n",
       "0             3664.436218               61085.809570              2615.120483   \n",
       "1             3651.190311               66969.478735              3174.572424   \n",
       "2             4216.986492               60068.894448              3516.282669   \n",
       "3             5228.507736               51064.547339              4180.973322   \n",
       "4             3980.598120               63751.125781              3355.710107   \n",
       "\n",
       "   Cloud_cloud_optical_depth  Cloud_surface_albedo  \\\n",
       "0                  15.568533              0.272292   \n",
       "1                   8.690601              0.256830   \n",
       "2                  21.103410              0.251101   \n",
       "3                  15.386899              0.262043   \n",
       "4                   8.114694              0.235847   \n",
       "\n",
       "   Cloud_sensor_azimuth_angle  Cloud_sensor_zenith_angle  \\\n",
       "0                  -12.628986                  35.632416   \n",
       "1                   30.359375                  39.557633   \n",
       "2                   15.377883                  30.401823   \n",
       "3                  -11.293399                  24.380357   \n",
       "4                   38.532263                  37.392979   \n",
       "\n",
       "   Cloud_solar_azimuth_angle  Cloud_solar_zenith_angle  emission  \n",
       "0                -138.786423                 30.752140  3.750994  \n",
       "1                -145.183930                 27.251779  4.025176  \n",
       "2                -142.519545                 26.193296  4.231381  \n",
       "3                -132.665828                 28.829155  4.305286  \n",
       "4                -141.509805                 22.204612  4.347317  \n",
       "\n",
       "[5 rows x 76 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data extraction\n",
    "data = pd.read_csv('D:/Kaggle Datasets/playground-series-s3e20/train.csv')\n",
    "# top 5 rows\n",
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset: (56896, 76)\n",
      "Valid Dataset: (15805, 76)\n",
      "Test Dataset: (6322, 76)\n"
     ]
    }
   ],
   "source": [
    "# data split\n",
    "## Train-Valid\n",
    "### Train-Test\n",
    "\n",
    "trainData, validData = train_test_split(data,test_size=0.2,random_state=42)\n",
    "trainData, testData = train_test_split(trainData,test_size=0.1,random_state=42)\n",
    "\n",
    "print(f'Train Dataset:', trainData.shape)\n",
    "print(f'Valid Dataset:',validData.shape)\n",
    "print(f'Test Dataset:', testData.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop columns that has more than 90% missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnsToDrop = {'ID_LAT_LON_YEAR_WEEK','UvAerosolLayerHeight_aerosol_height','UvAerosolLayerHeight_aerosol_pressure',\n",
    "                          'UvAerosolLayerHeight_aerosol_optical_depth','UvAerosolLayerHeight_sensor_zenith_angle',\n",
    "                          'UvAerosolLayerHeight_sensor_azimuth_angle','UvAerosolLayerHeight_solar_azimuth_angle',\n",
    "                          'UvAerosolLayerHeight_solar_zenith_angle'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainTarget = trainData['emission']\n",
    "trainData.drop(columns = columnsToDrop,inplace=True, axis=1)\n",
    "validData.drop(columns = columnsToDrop,inplace=True, axis=1)\n",
    "testData.drop(columns = columnsToDrop,inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute values with mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "impute = SimpleImputer(strategy='mean')\n",
    "\n",
    "trainImpute = impute.fit_transform(trainData)\n",
    "validImpute = impute.transform(validData)\n",
    "testImpute = impute.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainImputeData = pd.DataFrame(trainImpute,columns=trainData.columns)\n",
    "validImputeData = pd.DataFrame(validImpute,columns=validData.columns)\n",
    "testImputeData = pd.DataFrame(testImpute,columns=testData.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding data points\n",
    "1) Border country \n",
    "2) Nearby province\n",
    "3) Industrial region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# Country data\n",
    "# Path to the unzipped shapefile\n",
    "rwanda_map = gpd.read_file('D:/Kaggle Datasets/RWA_adm/RWA_adm0.shp')\n",
    "burundi_map = gpd.read_file('D:/Kaggle Datasets/Burundi/geoBoundaries-BDI-ADM0.shp')\n",
    "drc_map = gpd.read_file('D:/Kaggle Datasets/DRC/cod_admbnda_adm0_rgc_itos_20190911.shp')\n",
    "uganda_map = gpd.read_file('D:/Kaggle Datasets/Uganda/uga_admbnda_adm0_ubos_20200824.shp')\n",
    "tanzania_map = gpd.read_file('D:/Kaggle Datasets/Tanzania/tza_admbnda_adm0_20181019.shp')\n",
    "# Load the shapefile\n",
    "rwanda_map = rwanda_map[['NAME_0','geometry']]\n",
    "burundi_map = burundi_map[['shapeName','geometry']]\n",
    "drc_map = drc_map[['ADM0_FR','geometry']]\n",
    "uganda_map = uganda_map[['ADM0_EN','geometry']]\n",
    "tanzania_map = tanzania_map[['ADM0_EN','geometry']]\n",
    "\n",
    "mapData = pd.concat([rwanda_map,burundi_map,drc_map,uganda_map,tanzania_map],axis=0)\n",
    "mapData['Country'] = np.where(mapData['NAME_0'].notnull(),mapData['NAME_0'],np.where(mapData['shapeName'].notnull(),mapData['shapeName'],\n",
    "                                np.where(mapData['ADM0_FR'].notnull(),mapData['ADM0_FR'],mapData['ADM0_EN'])))\n",
    "mapData = mapData[['Country','geometry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Province data\n",
    "rwanda_map = gpd.read_file('D:/Kaggle Datasets/RWA_adm/RWA_adm1.shp')\n",
    "\n",
    "# Industrial region data\n",
    "industialRegion = gpd.read_file('D:/Kaggle Datasets/RWA_adm/RWA_adm2.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rwanda_map['Province_Name'] = np.where(rwanda_map['NAME_1']=='Amajyaruguru','Northern Province',\n",
    "                                       np.where(rwanda_map['NAME_1']=='Amajyepfo', 'Southern Province',\n",
    "                                                np.where(rwanda_map['NAME_1']=='Iburasirazuba','Eastern Province',\n",
    "                                                         np.where(rwanda_map['NAME_1']=='Iburengerazuba','Western Province',\n",
    "                                                                  np.where(rwanda_map['NAME_1']=='Umujyi wa Kigali','Kigali City','Rwanda')))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "industialRegion = industialRegion[(industialRegion['NAME_2'] == 'Gasabo')|(industialRegion['NAME_2'] == 'Kicukiro')|(industialRegion['NAME_2'] == 'Bugesera')|\\\n",
    "    (industialRegion['NAME_2'] == 'Huye')|(industialRegion['NAME_2'] == 'Rusizi')|(industialRegion['NAME_2'] == 'Nyabihu')|(industialRegion['NAME_2'] == 'Musanze')|\\\n",
    "    (industialRegion['NAME_2'] == 'Rwamagana')|(industialRegion['NAME_2'] == 'Rubavu')|(industialRegion['NAME_2'] == 'Muhanga')|\\\n",
    "    (industialRegion['NAME_2'] == 'Nyagatare')][['NAME_2','geometry']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class findLocation:\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "    def fit(self,dataset, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, dataset):\n",
    "        dataset['Country'] = dataset.apply(lambda row: self.find_location(row['latitude'],row['longitude'],mapData,'Country'), axis=1)\n",
    "        dataset['Province'] = dataset.apply(lambda row: self.find_location(row['latitude'],row['longitude'],rwanda_map,'Province_Name'), axis=1)\n",
    "        dataset['Nearest_Province'] = dataset.apply(lambda row: self.nearest_province_by_boundary(row['latitude'],row['longitude'],rwanda_map,'Province_Name'), axis=1)\n",
    "        dataset[['Nearest_Industrial_Region','Distance']] = dataset.apply(lambda row: self.nearest_industrial_by_boundary(row['latitude'],row['longitude'],industialRegion,'NAME_2'), axis=1, result_type='expand')\n",
    "        dataset['Province'].fillna('Nearest_Province',inplace = True)\n",
    "        return dataset\n",
    "\n",
    "\n",
    "    def find_location(self, latitude, longitude, targetMap, targetColumn):\n",
    "        point = Point(longitude, latitude)\n",
    "\n",
    "        for idx, row in targetMap.iterrows():\n",
    "            if row['geometry'].contains(point):\n",
    "                return row[targetColumn]\n",
    "            \n",
    "        return \"Unknown\"\n",
    "    \n",
    "    def nearest_province_by_boundary(self, latitude, longitude, targetMap, targetColumn):\n",
    "        point = Point(longitude, latitude)\n",
    "        # Find the province whose boundary is closest to the point\n",
    "        distances = targetMap['geometry'].boundary.distance(point)\n",
    "        return targetMap.loc[distances.idxmin(), targetColumn]\n",
    "    \n",
    "    def nearest_industrial_by_boundary(self, latitude, longitude, targetMap, targetColumn):\n",
    "        point = Point(longitude, latitude)\n",
    "        # Find the province whose boundary is closest to the point\n",
    "        distances = targetMap['geometry'].boundary.distance(point)\n",
    "        return targetMap.loc[distances.idxmin(), targetColumn], distances.idxmin()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classCall = findLocation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('find location', classCall)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_location(latitude, longitude, targetMap, targetColumn):\n",
    "    point = Point(longitude, latitude)\n",
    "\n",
    "    for idx, row in targetMap.iterrows():\n",
    "        if row['geometry'].contains(point):\n",
    "            return row[targetColumn]\n",
    "          \n",
    "    return \"Unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_province_by_boundary(latitude, longitude, targetMap, targetColumn):\n",
    "        point = Point(longitude, latitude)\n",
    "        # Find the province whose boundary is closest to the point\n",
    "        distances = targetMap['geometry'].boundary.distance(point)\n",
    "        return targetMap.loc[distances.idxmin(), targetColumn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_industrial_by_boundary(latitude, longitude, targetMap, targetColumn):\n",
    "    point = Point(longitude, latitude)\n",
    "    # Find the province whose boundary is closest to the point\n",
    "    distances = targetMap['geometry'].boundary.distance(point)\n",
    "    return targetMap.loc[distances.idxmin(), targetColumn], distances.idxmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainImputeData['Country'] = trainImputeData.apply(lambda row: find_location(row['latitude'],row['longitude'],mapData,'Country'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainImputeData['Province'] = trainImputeData.apply(lambda row: find_location(row['latitude'],row['longitude'],rwanda_map,'Province_Name'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainImputeData['Nearest_Province'] = trainImputeData.apply(lambda row: nearest_province_by_boundary(row['latitude'],row['longitude'],rwanda_map,'Province_Name'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainImputeData[['Industrial_Region','Distance']] = trainImputeData.apply(lambda row: nearest_industrial_by_boundary(row['latitude'],row['longitude'],industialRegion,'NAME_2'), axis=1, result_type='expand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainImputeData['Province'] = np.where(trainImputeData['Province']=='Unknown',trainImputeData['Nearest_Province'],trainImputeData['Province'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainImputeData.to_csv('D:/Kaggle Datasets/TrainDataTransformed.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validTransformData = pipeline.transform(validImputeData)\n",
    "testTransformData = pipeline.transform(testImputeData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VALID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "validImputeData['Country'] = validImputeData.apply(lambda row: find_location(row['latitude'],row['longitude'],mapData,'Country'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "validImputeData['Province'] = validImputeData.apply(lambda row: find_location(row['latitude'],row['longitude'],rwanda_map,'Province_Name'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "validImputeData['Nearest_Province'] = validImputeData.apply(lambda row: nearest_province_by_boundary(row['latitude'],row['longitude'],rwanda_map,'Province_Name'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "validImputeData[['Industrial_Region','Distance']] = validImputeData.apply(lambda row: nearest_industrial_by_boundary(row['latitude'],row['longitude'],industialRegion,'NAME_2'), axis=1, result_type='expand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "validImputeData['Province'] = np.where(validImputeData['Province']=='Unknown',validImputeData['Nearest_Province'],validImputeData['Province'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "validImputeData.to_csv('D:/Kaggle Datasets/validDataTransformed.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "testImputeData['Country'] = testImputeData.apply(lambda row: find_location(row['latitude'],row['longitude'],mapData,'Country'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "testImputeData['Province'] = testImputeData.apply(lambda row: find_location(row['latitude'],row['longitude'],rwanda_map,'Province_Name'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "testImputeData['Nearest_Province'] = testImputeData.apply(lambda row: nearest_province_by_boundary(row['latitude'],row['longitude'],rwanda_map,'Province_Name'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "testImputeData[['Industrial_Region','Distance']] = testImputeData.apply(lambda row: nearest_industrial_by_boundary(row['latitude'],row['longitude'],industialRegion,'NAME_2'), axis=1, result_type='expand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "testImputeData['Province'] = np.where(testImputeData['Province']=='Unknown',testImputeData['Nearest_Province'],testImputeData['Province'])\n",
    "testImputeData.to_csv('D:/Kaggle Datasets/testDataTransformed.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
